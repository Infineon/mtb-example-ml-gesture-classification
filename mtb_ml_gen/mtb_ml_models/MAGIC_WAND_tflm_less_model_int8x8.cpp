// This file is generated. Do not edit.
// Generated on: 27.09.2022 21:35:10

#include "tensorflow/lite/c/builtin_op_data.h"
#include "tensorflow/lite/c/common.h"
#include "tensorflow/lite/micro/kernels/micro_ops.h"
#include "tensorflow/lite/micro/compatibility.h"
#include "tensorflow/lite/micro/micro_context.h"
#if LOG_OP_INPUTS
#include "tensorflow/lite/micro/micro_invoke_log.h"
#endif

#if TF_LITE_MICRO_USE_OFFLINE_OP_USER_DATA
#include "tensorflow/lite/micro/kernels/ifx_common/offline_prepare_utils.h" 
#endif  // TF_LITE_MICRO_USE_OFFLINE_OP_USER_DATA


#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#endif

#if TF_LITE_MICRO_USE_OFFLINE_OP_USER_DATA
#include "tensorflow/lite/micro/kernels/ifx_cmsis_nn/add_op_data.h"
#include "tensorflow/lite/micro/kernels/ifx_cmsis_nn/conv_op_data.h"
#include "tensorflow/lite/micro/kernels/ifx_cmsis_nn/depthwise_conv_op_data.h"
#include "tensorflow/lite/micro/kernels/ifx_cmsis_nn/fully_connected_op_data.h"
#include "tensorflow/lite/micro/kernels/ifx_cmsis_nn/mul_op_data.h"
#include "tensorflow/lite/micro/kernels/ifx_cmsis_nn/pooling_op_data.h"
#include "tensorflow/lite/micro/kernels/ifx_cmsis_nn/softmax_op_data.h"
#include "tensorflow/lite/micro/kernels/ifx_cmsis_nn/svdf_op_data.h"
#endif  // TF_LITE_MICRO_USE_OFFLINE_OP_USER_DATA
namespace {


constexpr int kTensorArenaSize = 14692;
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);


template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};


enum used_operators_e {
  OP_CONV_2D, OP_MAX_POOL_2D, OP_MUL, OP_ADD, OP_MEAN, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};


struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};

struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
  };


TfLiteContext ctx{};

// Tensor table with space for -1-th element used
// designate missing optional inputs/outputs.
TfLiteTensor tflTensorsWithMinus1[23];
     
TfLiteEvalTensor evalTensors[22];

TfLiteTensor * const tflTensors = tflTensorsWithMinus1+1;

TfLiteRegistration registrations[OP_LAST];
constexpr size_t kOpNodesCount = 10;


TfLiteNode tflNodes[kOpNodesCount];

const TfArray<4, int> tensor_dimension0 = { 4, { 1, 128, 6, 1, } };
const TfArray<1, float> quant0_scale = { 1, { 0.0078371148556470871, } };
const TfArray<1, int> quant0_zero = { 1, { 0, } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(8) int32_t tensor_data1[2] = { 
    1, 2, 
};
const TfArray<1, int> tensor_dimension1 = { 1, { 2, } };
const ALIGN(8) int8_t tensor_data2[16*3*3*1] = { 
  /* [0][0][][] */ 6, -112, 127, 
  /* [0][1][][] */ 108, -55, 46, 
  /* [0][2][][] */ 75, -57, -14, 
  /* [1][0][][] */ 35, -44, 127, 
  /* [1][1][][] */ 21, -46, 85, 
  /* [1][2][][] */ 88, -25, 53, 
  /* [2][0][][] */ 7, -61, -75, 
  /* [2][1][][] */ 83, -106, -119, 
  /* [2][2][][] */ 127, -19, -109, 
  /* [3][0][][] */ 66, 127, 119, 
  /* [3][1][][] */ -23, 85, 40, 
  /* [3][2][][] */ 20, 77, 37, 
  /* [4][0][][] */ 74, 32, 127, 
  /* [4][1][][] */ 74, 2, 101, 
  /* [4][2][][] */ 96, 28, 82, 
  /* [5][0][][] */ -127, 9, -62, 
  /* [5][1][][] */ 11, -23, -31, 
  /* [5][2][][] */ -22, 6, 15, 
  /* [6][0][][] */ 60, -52, -127, 
  /* [6][1][][] */ 60, -30, -43, 
  /* [6][2][][] */ 73, -38, -98, 
  /* [7][0][][] */ -103, 29, 92, 
  /* [7][1][][] */ -65, 92, 17, 
  /* [7][2][][] */ -29, 127, 93, 
  /* [8][0][][] */ 93, -23, -8, 
  /* [8][1][][] */ 127, -29, -59, 
  /* [8][2][][] */ 72, 41, -74, 
  /* [9][0][][] */ 11, 60, -59, 
  /* [9][1][][] */ 23, -12, -127, 
  /* [9][2][][] */ -12, 28, -78, 
  /* [10][0][][] */ 21, 127, -80, 
  /* [10][1][][] */ 8, 55, -28, 
  /* [10][2][][] */ -69, 56, 37, 
  /* [11][0][][] */ -3, 48, -98, 
  /* [11][1][][] */ -18, 14, -74, 
  /* [11][2][][] */ 32, -31, -127, 
  /* [12][0][][] */ 13, 113, 87, 
  /* [12][1][][] */ 5, 102, 41, 
  /* [12][2][][] */ 16, 127, 24, 
  /* [13][0][][] */ 10, 35, -45, 
  /* [13][1][][] */ -127, 2, 63, 
  /* [13][2][][] */ -118, -93, -47, 
  /* [14][0][][] */ 91, 7, -126, 
  /* [14][1][][] */ 60, 93, -65, 
  /* [14][2][][] */ 55, 127, -127, 
  /* [15][0][][] */ 83, 3, -14, 
  /* [15][1][][] */ 40, -127, -21, 
  /* [15][2][][] */ 105, 32, -30, 
};
const TfArray<4, int> tensor_dimension2 = { 4, { 16, 3, 3, 1, } };
const TfArray<16, float> quant2_scale = { 16, { 0.002663320628926158, 0.0028318052645772696, 0.001996323000639677, 0.0025156224146485329, 0.0036399716045707464, 0.0033221149351447821, 0.001927410950884223, 0.0022333071101456881, 0.0038580154068768024, 0.0037991120480000973, 0.0030196835286915302, 0.0035889642313122749, 0.0036783837713301182, 0.0021165800280869007, 0.0023136059753596783, 0.0025106947869062424, } };
const TfArray<16, int> quant2_zero = { 16, { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, } };
const TfLiteAffineQuantization quant2 = { (TfLiteFloatArray*)&quant2_scale, (TfLiteIntArray*)&quant2_zero, 0 };
const ALIGN(8) int32_t tensor_data3[16] = { 
    219, -2533, 1047, 4208, 282, 1264, 805, 3117, 3706, 15, 
    808, 200, -3, 5508, 6066, 962, 
};
const TfArray<1, int> tensor_dimension3 = { 1, { 16, } };
const TfArray<16, float> quant3_scale = { 16, { 2.0872748791589402e-05, 2.2193182303453796e-05, 1.5645413441234268e-05, 1.9715222151717171e-05, 2.8526876121759415e-05, 2.6035795599455014e-05, 1.5105340935406275e-05, 1.7502683476777747e-05, 3.0235709346015938e-05, 2.9774077120237052e-05, 2.3665606931899674e-05, 2.8127124096499756e-05, 2.8827915230067447e-05, 1.6587880963925272e-05, 1.81319956027437e-05, 1.9676603187690489e-05, } };
const TfArray<16, int> quant3_zero = { 16, { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, } };
const TfLiteAffineQuantization quant3 = { (TfLiteFloatArray*)&quant3_scale, (TfLiteIntArray*)&quant3_zero, 0 };
const ALIGN(8) int8_t tensor_data4[16] = { 
    -3, 127, 23, 54, 71, 24, 56, 21, 41, 36, 
    63, 29, 13, 13, 46, 74, 
};
const TfArray<1, int> tensor_dimension4 = { 1, { 16, } };
const TfArray<1, float> quant4_scale = { 1, { 0.13693822920322418, } };
const TfArray<1, int> quant4_zero = { 1, { -128, } };
const TfLiteAffineQuantization quant4 = { (TfLiteFloatArray*)&quant4_scale, (TfLiteIntArray*)&quant4_zero, 0 };
const ALIGN(8) int8_t tensor_data5[16] = { 
    18, 82, 14, -34, 66, -21, 27, -47, -128, 80, 
    26, 69, 82, -93, -90, 6, 
};
const TfArray<1, int> tensor_dimension5 = { 1, { 16, } };
const TfArray<1, float> quant5_scale = { 1, { 0.014519871212542057, } };
const TfArray<1, int> quant5_zero = { 1, { 127, } };
const TfLiteAffineQuantization quant5 = { (TfLiteFloatArray*)&quant5_scale, (TfLiteIntArray*)&quant5_zero, 0 };
const ALIGN(8) int8_t tensor_data6[32*3*3*16] = { 
  /* [0][0][][] */ -7,-1,-28,-115,-58,-2,-17,12,-97,81,14,127,-105,-26,23,-11, -61,38,-36,-64,-13,1,-11,1,-10,63,92,51,-76,8,-77,-4, 42,18,30,-67,-48,101,53,68,18,7,32,17,-75,11,-81,17, 
  /* [0][1][][] */ 62,11,-12,-55,-7,11,21,19,28,80,44,37,-29,56,61,59, -15,35,-3,-75,-20,34,29,99,-38,26,46,88,-37,2,-5,-8, 18,6,19,-71,-93,31,36,48,52,-17,8,3,-112,26,-96,-12, 
  /* [0][2][][] */ 15,61,71,-12,57,45,55,116,27,85,25,38,-1,96,26,88, 34,94,70,-25,-18,66,85,121,-32,55,42,-6,-52,34,23,87, 12,23,13,-72,-71,53,73,-14,84,-28,56,-76,-110,-4,-120,32, 
  /* [1][0][][] */ 9,-20,-5,34,-29,18,16,18,-127,39,16,35,47,16,0,-9, 11,-46,18,9,1,-6,-10,31,1,16,34,-30,16,-19,28,20, 7,-23,-25,-4,40,-13,-12,-40,18,-34,25,-37,2,-21,-21,27, 
  /* [1][1][][] */ 8,-12,-22,-11,35,46,-20,-5,-118,75,30,53,-6,33,-4,-15, -7,-73,2,-5,8,-11,-8,37,-4,21,40,17,35,20,43,0, -9,-8,-13,-34,60,-3,-1,-45,46,-29,10,-26,-33,-29,-2,39, 
  /* [1][2][][] */ 2,-14,3,-18,18,2,2,-1,-126,37,23,36,4,33,1,3, 4,-64,-16,-7,-17,-8,-24,27,-29,1,51,-35,-18,9,-3,-19, -4,-9,-17,41,68,-19,0,-30,68,-24,15,-57,12,-34,21,29, 
  /* [2][0][][] */ -15,-29,-39,25,50,11,-3,10,-111,-3,-34,9,37,-16,-28,-54, -9,-20,10,43,28,-12,-17,7,-10,-9,18,-52,10,8,53,-11, 10,10,3,6,21,-44,3,4,23,-60,24,-10,-6,-22,-12,-20, 
  /* [2][1][][] */ -5,-19,-29,-30,27,20,13,13,-127,18,4,42,-6,-1,-49,-42, -10,-34,-1,44,4,11,-3,39,-44,18,36,13,14,20,4,6, 40,-42,-6,27,54,-16,-2,-27,78,-9,18,-46,-13,-40,39,1, 
  /* [2][2][][] */ -5,-16,-13,-14,-6,30,-3,65,-76,57,17,53,26,17,-18,-8, -4,-47,23,-17,-14,15,17,59,-35,25,63,35,-39,3,-36,-10, -15,-52,9,-29,49,2,-5,-20,59,-48,27,-33,-26,3,-13,32, 
  /* [3][0][][] */ 12,2,30,5,-6,30,56,-12,120,-86,-44,-54,27,-7,-3,45, 43,49,25,34,40,18,18,42,40,-28,-10,-2,11,14,18,68, 34,25,-10,-52,-32,5,26,1,-15,-32,5,-19,-65,4,-67,-11, 
  /* [3][1][][] */ -45,-40,-9,0,-13,-12,-11,-12,127,-46,6,-1,9,-44,-13,13, -11,25,21,27,56,5,36,-23,8,-28,-4,25,4,-19,14,14, 3,46,22,-60,-25,21,-16,5,-33,-32,-39,-29,-50,8,-44,3, 
  /* [3][2][][] */ -89,14,-46,-22,-43,-63,-42,-30,104,0,-50,17,29,-62,-16,-51, 6,-15,6,17,14,0,4,35,47,-49,14,-33,28,11,17,-21, 9,53,-16,-52,-14,-12,3,37,-55,-59,-21,-23,-68,2,-44,0, 
  /* [4][0][][] */ -28,47,-5,-4,-42,-37,-6,-72,118,29,-19,15,-55,6,-33,-2, -49,28,-94,35,-33,-19,-73,-47,15,44,76,103,39,-32,52,-86, -79,-48,-56,20,-37,-20,-11,-19,-78,4,-43,0,23,-25,-78,-90, 
  /* [4][1][][] */ 14,-1,-8,-9,-32,-51,-60,-58,127,-16,56,16,-15,-56,10,12, -34,8,-45,84,7,-69,-76,-28,1,73,31,33,39,-32,25,-55, -5,-8,-23,-5,-38,15,-19,-42,-47,64,-54,70,1,-21,-32,-45, 
  /* [4][2][][] */ -27,-4,-18,6,-74,-56,-55,-88,101,-7,13,7,-39,-25,31,-13, -19,16,-48,99,-35,-42,-41,-51,6,34,39,45,40,-30,84,-43, -11,9,12,-97,-45,-5,-60,-47,-41,50,-11,86,-40,-6,-19,14, 
  /* [5][0][][] */ -53,-13,22,28,101,-15,-58,-55,74,-72,-62,-99,20,-1,-79,14, 17,-71,38,-16,3,-9,-6,-9,-16,-22,-31,-47,-39,-34,39,29, -20,45,-10,-106,-118,67,62,-26,-30,24,-30,-33,-60,33,-13,2, 
  /* [5][1][][] */ 32,21,23,-56,63,24,25,-23,127,-96,-101,-31,77,-12,-20,49, -74,-33,72,-52,42,6,96,-20,-38,-13,-55,-31,-13,-31,10,-26, -8,24,39,-49,-54,36,49,34,-68,-13,3,-88,-58,25,-91,29, 
  /* [5][2][][] */ -3,-25,-16,-45,113,31,-55,-66,89,-110,-40,-98,55,23,34,16, -35,-7,32,-23,-36,-46,87,-43,41,15,-46,-1,6,-34,-7,35, 18,-20,22,-51,-110,60,31,74,-55,-92,-52,-75,10,-46,-51,16, 
  /* [6][0][][] */ 13,26,-57,43,13,-39,-68,18,76,51,43,34,5,-48,58,-36, -3,-25,-25,-77,-46,23,7,-54,13,28,-61,18,-4,26,-65,32, 3,2,-21,114,60,15,-11,1,-10,40,-11,5,61,32,23,10, 
  /* [6][1][][] */ 25,19,-55,-13,26,-39,-76,26,48,26,-12,26,-13,-4,27,-37, 25,-29,-31,-54,-46,-10,-5,-46,13,30,5,-5,-43,0,0,-20, -9,-15,-17,127,46,16,-26,-23,-33,20,26,-6,80,-27,25,-17, 
  /* [6][2][][] */ 9,50,-49,33,5,-17,-48,52,2,23,-4,-16,49,3,91,-30, -18,-56,-28,-86,-5,20,8,-61,37,25,-40,37,-43,-1,-41,-5, -2,2,8,119,68,-18,-3,2,6,14,11,-9,93,32,48,-29, 
  /* [7][0][][] */ 13,18,-23,-15,90,-9,-18,10,-96,50,23,-3,-11,-21,-54,-58, 0,-82,0,-15,-11,33,-12,34,19,86,51,63,-8,16,4,-1, 23,8,45,8,-10,-9,18,25,47,-43,40,-33,-28,14,-60,24, 
  /* [7][1][][] */ 6,-35,13,-26,127,40,-29,8,-94,68,10,38,21,8,-26,-45, -16,-78,14,-39,-35,18,2,52,-7,51,88,32,7,34,46,3, 11,-34,12,-71,8,50,43,-8,56,-10,37,-77,-82,-20,-59,24, 
  /* [7][2][][] */ -35,-7,-7,-68,16,39,15,-30,-100,38,31,40,-27,5,-32,16, -24,-83,20,-7,-30,21,4,86,-37,25,53,32,44,27,24,-12, 16,-36,13,-64,61,-2,26,24,64,-84,34,-91,-48,-23,-38,37, 
  /* [8][0][][] */ 5,-9,-17,-71,56,18,-73,-93,-77,67,59,83,-38,-54,-17,-61, -9,35,23,-27,-47,17,17,53,-12,120,5,127,-37,57,58,7, 35,64,22,-70,-90,47,-17,31,-8,-18,60,-26,-6,9,-110,37, 
  /* [8][1][][] */ -3,6,10,-16,-30,26,29,-46,-110,77,66,87,-30,4,5,-13, -44,-26,0,-71,-48,33,3,33,-39,86,-10,49,1,57,52,39, -13,-37,53,-95,-81,16,52,104,51,-54,72,-8,-89,32,-91,68, 
  /* [8][2][][] */ -12,-15,65,-27,24,31,54,-11,-82,81,38,80,-40,43,-43,28, -9,-16,15,-8,-70,43,42,68,-13,71,57,29,39,47,47,50, 27,11,65,-106,5,34,29,50,33,-76,-18,-40,-88,-38,-89,94, 
  /* [9][0][][] */ 10,-33,24,-78,-20,9,38,-57,-25,100,22,53,-81,10,-19,-1, -27,18,9,-87,-96,17,14,-32,-40,82,68,99,-58,32,-14,-19, 15,47,30,-56,-91,93,24,96,-19,13,71,-24,-85,53,-33,11, 
  /* [9][1][][] */ 37,7,7,-20,-72,39,21,38,-23,41,13,57,-64,1,34,44, 2,45,41,-14,-47,23,24,48,-20,66,25,24,-44,56,-1,-16, 36,42,18,-122,-53,37,7,56,16,-26,25,-43,-12,39,-55,33, 
  /* [9][2][][] */ 79,64,32,6,-61,55,62,116,42,17,-2,40,32,33,75,77, 49,59,62,17,9,59,56,127,42,-68,2,-85,-48,22,49,83, 43,70,50,-84,46,11,55,-5,42,-44,-29,-12,-63,37,-13,16, 
  /* [10][0][][] */ -77,-76,-76,80,58,-100,-54,-45,-17,-30,-66,-56,72,-95,60,-77, -43,-36,-34,46,44,-79,-32,-55,-23,-11,-31,-28,43,-47,5,-34, 2,-6,-5,-7,19,-24,-20,-16,28,1,-3,-34,-12,-44,43,-25, 
  /* [10][1][][] */ -57,-127,-90,41,14,-116,-68,-69,8,47,-14,14,55,-80,18,-52, -33,-31,-40,11,-28,-40,-52,-49,-26,9,-10,-28,28,-34,-20,-57, 9,-8,-13,15,-15,18,-9,-37,-25,3,-22,4,-20,-19,19,-37, 
  /* [10][2][][] */ -84,-63,-69,-8,-19,-54,-79,-105,-22,92,33,69,-13,-83,-40,-57, -44,-31,-46,-8,-34,-15,-24,-13,-52,52,15,41,-13,-3,-61,-59, 2,30,-18,-13,-82,26,-4,19,-57,-5,-43,-41,-2,0,19,-37, 
  /* [11][0][][] */ 101,97,59,-6,-51,71,98,44,56,39,52,66,-59,82,2,54, 23,90,10,19,-65,51,32,54,4,14,65,12,-2,56,44,40, 21,48,44,-61,-34,6,24,-14,22,-4,-12,0,18,25,-16,30, 
  /* [11][1][][] */ 29,87,38,30,-65,59,104,104,44,-70,19,-67,-37,30,15,100, 31,87,38,48,-45,48,47,47,-22,-24,-7,-35,-22,72,33,55, 29,0,4,-71,20,52,45,-23,16,9,5,-16,6,14,-15,39, 
  /* [11][2][][] */ 73,107,73,75,-60,53,70,54,57,-103,-27,-127,-2,95,63,49, 20,64,34,63,-11,43,72,22,2,-53,-47,-4,-2,21,52,45, 36,0,22,-55,41,-9,33,5,19,13,26,-16,-16,-15,33,7, 
  /* [12][0][][] */ 47,5,42,31,-10,43,62,-10,-15,-63,-17,-89,-12,64,38,9, 63,66,30,-36,61,20,22,35,-62,-74,4,-55,5,-16,-33,55, -8,5,2,-38,-2,15,30,-30,10,-37,-85,-97,-12,23,-86,16, 
  /* [12][1][][] */ -24,1,-21,88,62,6,-2,35,-42,-64,-46,-22,13,48,66,-27, 42,19,1,63,34,-64,-26,-16,-41,-82,-8,-68,17,-101,5,16, 21,39,27,-20,62,5,3,-15,24,-71,-57,-124,-77,-6,-81,34, 
  /* [12][2][][] */ -7,-55,-73,78,103,-49,-83,0,-52,-63,-2,-44,44,-7,97,-57, 17,-36,-49,55,61,-34,-18,-28,-63,-98,-60,-127,-3,-107,-8,-17, -16,52,8,10,58,-30,12,-34,26,-59,-25,-117,-11,-102,-86,2, 
  /* [13][0][][] */ 12,-4,23,26,-16,66,26,74,-112,-91,-58,-102,87,54,-31,36, -15,-54,26,18,48,46,37,8,1,-21,-27,1,31,62,63,22, -11,-41,-5,-57,22,-7,15,-8,41,38,-10,45,-30,-5,51,23, 
  /* [13][1][][] */ 60,-32,44,47,-21,55,50,13,-127,5,-58,-32,41,-4,-66,5, 10,-58,30,77,60,68,45,2,-62,16,-21,-4,60,42,28,24, -25,1,11,49,36,13,-24,-23,14,-22,32,17,33,3,81,26, 
  /* [13][2][][] */ 17,1,34,-47,-8,39,9,5,-60,53,-12,32,-72,-21,-58,6, 3,-42,36,5,39,78,-4,-6,-63,12,6,32,39,78,-36,25, 12,-31,20,84,10,-10,-15,-18,38,-21,6,-6,59,19,72,-23, 
  /* [14][0][][] */ -90,-70,-125,30,-24,-34,-74,-127,102,38,-34,-8,-12,-112,-22,-120, -23,1,-44,22,28,-24,-37,-21,-31,14,-39,22,55,-61,68,-88, -13,-40,-35,18,39,-52,15,-52,-5,-24,-56,12,7,-26,73,-3, 
  /* [14][1][][] */ -84,-68,-60,38,10,-76,-33,-57,116,11,-12,26,73,-72,13,-94, -50,-32,-55,-8,27,-73,4,-70,-3,-8,-34,42,-20,-58,35,-75, -31,-21,10,34,23,-9,-4,-18,-13,17,-4,5,21,-59,21,-34, 
  /* [14][2][][] */ -11,19,-69,26,5,-121,-45,-89,73,10,16,80,55,-50,-26,2, -52,-15,-46,-26,-33,-45,-44,-61,12,23,-23,63,-34,-32,11,-83, -24,-10,-35,-22,7,-12,-29,2,-68,-29,-59,-5,-10,-3,7,-21, 
  /* [15][0][][] */ 22,21,-2,-36,-49,21,-33,-31,21,-5,11,3,-37,-29,24,0, 17,-23,-2,-12,-6,22,-29,-5,-4,0,-24,-25,17,30,-18,-18, 9,7,-18,120,26,11,2,27,31,36,11,55,65,19,38,-7, 
  /* [15][1][][] */ 4,-3,-17,-11,-22,9,-6,-30,14,-6,11,-36,-5,-7,-9,-37, -26,-37,-11,-41,19,36,8,7,-21,-13,-13,-3,14,4,-26,-33, -27,-38,7,127,34,28,-15,28,-14,35,10,52,105,12,31,-5, 
  /* [15][2][][] */ -15,-11,-38,-9,-7,-18,-36,-10,34,-8,14,-3,-51,-44,13,-21, -7,-17,0,-15,-5,50,-7,-5,-17,-1,-12,0,8,21,-6,8, -15,-2,-18,115,53,2,-36,-14,9,10,11,14,103,11,50,-23, 
  /* [16][0][][] */ 10,-18,38,45,97,24,23,-38,93,30,-16,-21,86,25,20,-1, 17,-39,45,-36,-15,-30,17,-53,2,-42,-86,-39,9,18,-109,32, 19,58,70,-73,-73,45,19,50,-39,-23,-29,-69,-75,35,-34,51, 
  /* [16][1][][] */ 19,-45,2,13,127,-17,14,-47,68,0,-76,72,74,14,11,16, -43,-47,31,-74,-19,-28,23,-13,-53,-71,-39,-27,5,-3,-78,-17, 21,63,-22,-109,-88,42,47,26,-21,-52,-34,-7,-79,47,-26,65, 
  /* [16][2][][] */ -1,-54,53,17,113,-17,-8,-6,94,52,-8,-64,24,-36,-4,55, -17,3,47,-51,-36,-37,73,-7,-60,-71,-47,-34,-51,-46,-75,21, 28,56,61,-67,-79,-38,28,-25,33,12,-7,-7,-116,39,-57,-1, 
  /* [17][0][][] */ 25,43,19,-119,-63,59,23,-20,55,72,53,97,-122,-1,-15,86, 41,100,42,-47,-112,111,38,74,-5,25,38,92,-61,87,-31,23, 34,86,15,-53,-32,74,-4,64,-34,-36,16,-64,-21,12,-53,4, 
  /* [17][1][][] */ 1,74,48,-16,-48,48,79,35,50,-12,20,-33,-69,4,75,66, 14,99,16,36,-51,43,13,51,-19,-59,-11,-30,-36,29,29,42, 64,59,49,-98,12,1,15,24,-1,-27,-15,-16,1,-22,-34,56, 
  /* [17][2][][] */ 70,50,16,87,-29,22,32,88,13,-106,-42,-127,29,33,125,93, 20,26,-4,80,13,-54,7,1,32,-56,-77,-51,12,-55,63,24, 81,42,58,-62,61,-15,7,-5,31,-7,-50,-31,26,-3,-18,41, 
  /* [18][0][][] */ 17,27,-26,21,38,-29,-29,-9,46,7,5,18,4,-16,66,-10, 1,-59,12,-57,-22,18,17,-19,19,19,-8,1,-55,14,-55,-7, -5,-5,-7,74,42,11,-10,11,-19,11,3,-12,57,29,9,3, 
  /* [18][1][][] */ 5,1,-9,11,-5,-39,-14,-14,20,22,9,23,-14,3,47,-1, -1,-33,4,-15,-29,9,6,-9,4,3,-9,-4,-4,9,-21,-6, 21,-7,-2,111,43,9,-21,12,-17,-5,20,21,77,-7,29,-13, 
  /* [18][2][][] */ -7,21,-3,31,21,-31,-16,10,5,10,29,7,-5,-10,73,-7, -3,-44,-5,-52,-30,13,-1,-41,25,10,-44,24,-48,-25,-48,3, 0,6,11,127,38,-3,7,16,-15,-12,10,9,62,-4,37,12, 
  /* [19][0][][] */ -36,-28,-3,-20,56,18,-20,57,-127,7,-9,-4,11,25,-54,-8, 18,-33,23,-39,14,-4,7,34,-41,40,75,39,12,-18,24,15, 4,-30,12,-19,6,16,-13,-28,28,-38,-1,-26,-50,-28,-37,0, 
  /* [19][1][][] */ -15,-18,9,11,66,9,-2,-3,-104,4,1,25,-9,29,-49,-28, 8,-56,0,19,6,-2,-2,57,-4,44,46,10,51,6,41,-6, 34,-2,-9,-24,28,-13,-10,-27,51,-31,5,-33,-10,3,4,45, 
  /* [19][2][][] */ -19,-16,-32,-31,44,4,-27,22,-84,54,-6,35,-36,19,-44,-26, 0,-72,-5,20,30,4,13,56,-38,-27,16,-16,15,21,36,-7, 3,-13,17,66,17,-19,14,-11,78,-44,-22,-25,-8,-49,-8,-2, 
  /* [20][0][][] */ 34,30,-21,3,119,24,-68,29,-51,-3,-1,13,7,-10,-85,10, 20,-70,29,-8,22,-11,43,-7,31,69,57,36,-25,-24,54,19, 42,13,7,65,-64,26,-5,7,23,-2,-6,-19,-2,-12,-43,-38, 
  /* [20][1][][] */ 55,31,-9,-46,115,40,-48,-14,-36,34,40,53,-38,0,-13,-38, 5,-63,22,-35,-4,-31,59,-8,59,-18,14,12,7,-25,8,59, 11,6,2,22,-57,-20,-8,28,9,-35,4,4,-4,33,-40,-9, 
  /* [20][2][][] */ 38,47,-42,-44,127,-8,-59,12,-25,9,-1,49,32,-21,-35,-21, -42,-93,50,-34,1,-7,40,-14,38,32,-55,63,4,-18,22,15, 36,-3,-37,-4,-62,19,6,32,-23,-38,1,-3,-70,-13,-55,-36, 
  /* [21][0][][] */ -38,22,-53,66,50,-96,-35,-54,70,8,-13,48,17,-94,30,-43, 6,22,-69,60,43,-56,-32,-29,-21,-33,-88,15,89,-45,5,-3, 16,2,-13,-80,-24,-55,29,-36,-55,-5,-15,-7,-70,26,2,8, 
  /* [21][1][][] */ -88,-51,13,38,45,-90,-51,-100,100,49,17,38,35,-87,38,-60, -39,-4,-49,27,64,-66,-9,7,-21,-10,-40,31,33,-14,-13,-16, -40,-15,-17,-21,-51,-23,11,-17,-16,-10,-51,0,-34,-9,8,-47, 
  /* [21][2][][] */ -80,-31,-12,44,2,-77,-32,-78,127,112,31,106,1,-109,28,-78, -54,18,-72,-3,66,-51,-52,-26,-18,57,-31,35,52,-41,-1,6, -26,-4,-31,-24,-85,1,-37,40,-31,-4,-64,-67,17,21,33,-11, 
  /* [22][0][][] */ 62,80,76,68,-29,41,26,79,-43,-76,23,-127,22,12,6,55, 12,29,72,39,-44,45,80,12,34,17,0,2,-8,54,49,37, -5,33,-19,12,19,7,-30,-2,26,49,18,52,45,-14,24,-47, 
  /* [22][1][][] */ 35,62,64,20,-50,53,108,29,-47,-44,-44,-86,11,75,8,76, 10,-29,64,28,-54,76,71,8,-26,-33,12,-20,-21,45,34,57, -34,28,-7,-7,62,-8,-18,23,29,-12,4,34,38,-15,49,18, 
  /* [22][2][][] */ 33,51,100,-11,-42,66,96,-12,-28,13,-41,-1,-19,29,-53,57, 7,-3,47,22,-6,38,42,18,-3,-15,-21,-33,31,55,25,-3, -16,-4,-16,1,39,31,29,-2,13,15,25,48,79,26,105,-17, 
  /* [23][0][][] */ 20,104,-13,75,93,33,-39,-16,-16,-76,-11,-127,6,-39,9,32, -2,64,8,64,41,-54,9,70,-17,-92,-8,-46,41,-49,-24,4, 3,38,12,-2,47,-88,-16,-64,55,7,-49,-74,20,-44,-13,-6, 
  /* [23][1][][] */ -17,30,-24,79,30,-51,-37,23,54,-72,-28,-22,44,-14,26,22, -27,35,-29,40,38,-67,-36,-32,-15,-13,-26,-29,6,-60,-12,-14, 46,-6,-12,16,55,31,-22,-49,-5,-78,-33,-72,-50,-37,21,-29, 
  /* [23][2][][] */ -38,14,-44,63,81,-78,-26,-13,35,-2,20,3,8,-80,2,-44, -24,-4,-34,-63,-57,-64,-14,-28,-41,7,8,-41,16,-68,-48,-49, 12,46,2,9,-40,35,35,1,-48,-4,2,-54,-8,-28,-6,-18, 
  /* [24][0][][] */ -11,-19,43,-84,-10,49,-25,-1,50,19,-7,26,-27,-20,2,-27, -7,55,-21,53,61,-3,-11,32,23,16,39,32,4,22,-1,-32, 26,-18,-20,126,-2,-24,0,-2,9,55,23,9,50,-5,13,-19, 
  /* [24][1][][] */ 18,-5,-10,-46,-43,22,-10,-8,10,3,3,5,-73,-12,-32,-31, 28,1,-58,5,63,28,-15,23,24,7,54,42,40,25,10,-9, -50,-41,1,31,-45,-16,28,51,-33,80,36,31,29,-10,-20,9, 
  /* [24][2][][] */ -5,-45,36,-82,-7,15,-15,-74,14,19,-15,-20,-39,-3,-5,-6, 27,-1,-28,-3,127,14,-44,29,-11,44,44,-11,27,10,51,-10, -1,-68,0,64,-10,-19,22,37,0,26,31,50,8,12,12,23, 
  /* [25][0][][] */ 50,44,14,33,49,-28,29,-16,118,-47,-62,18,83,4,-35,112, -61,72,6,19,-52,-4,39,-8,-58,-70,-99,-27,-23,-5,-12,30, 29,44,58,-87,-89,67,54,40,-12,-33,-51,-14,-47,6,-57,15, 
  /* [25][1][][] */ 21,-47,38,50,53,16,68,-1,109,-35,-19,4,5,39,-17,5, -6,12,28,1,-11,-9,62,34,-45,-21,-53,-21,-29,18,-72,21, -2,32,20,-73,-53,-12,5,-22,-52,-20,-68,43,-87,-25,-7,12, 
  /* [25][2][][] */ 50,24,13,32,74,28,65,18,57,-58,-33,-16,44,40,-16,30, 44,70,-47,-23,1,53,10,77,-44,-84,-127,-60,-25,44,-27,-32, 21,29,-7,-97,-122,-8,71,6,10,-1,32,2,-38,49,-16,6, 
  /* [26][0][][] */ 8,6,11,-5,116,-1,-49,20,-100,9,-1,3,-30,6,-70,6, -9,-26,11,56,52,-20,-22,46,44,15,29,33,48,-26,45,28, -6,-22,29,-7,-48,-30,19,-27,24,4,-25,12,25,21,-5,8, 
  /* [26][1][][] */ 35,20,-13,-63,101,6,-2,7,-102,27,5,31,-13,5,-44,-13, -8,-25,-20,40,40,13,1,45,35,22,45,39,40,-23,28,21, -9,-37,-3,46,-36,-7,17,12,-6,33,20,1,-13,11,-16,-19, 
  /* [26][2][][] */ 36,-12,0,-25,127,13,9,9,-126,42,50,26,-32,0,-55,12, 13,-38,-18,53,61,-2,18,49,55,-2,37,-23,78,-7,35,20, -11,-17,26,6,-52,3,-2,-9,-36,18,28,23,55,11,17,-3, 
  /* [27][0][][] */ -8,44,-45,-13,57,-17,-127,-33,99,30,39,12,-1,-84,84,-21, -36,-37,28,51,36,-46,46,11,40,-8,10,10,56,-10,-7,6, -34,12,1,-103,-74,20,7,-45,-34,23,-86,49,-33,-12,-21,-21, 
  /* [27][1][][] */ 32,41,0,-25,47,-47,-15,-21,77,36,12,29,-62,-65,63,-5, -59,-56,25,71,49,-53,-13,-8,59,6,-5,33,23,-38,-18,19, -2,25,-26,-93,-50,21,-24,16,-74,-37,-32,23,-29,6,-68,-12, 
  /* [27][2][][] */ 3,4,-69,-27,-34,-57,-72,-25,124,72,36,72,-23,-123,85,-23, 9,-14,-9,20,56,-6,28,-75,36,34,-4,41,85,-64,-33,23, -25,-15,-2,-41,-97,-27,25,3,-74,-33,-32,-11,-22,34,-30,-24, 
  /* [28][0][][] */ -15,-15,8,-48,-26,23,2,-32,31,-15,-75,-26,-17,3,-36,1, -12,-8,25,-35,15,32,-25,-10,-1,-1,4,-9,3,8,-8,17, 0,-14,-14,67,25,-6,0,14,-32,20,54,31,92,15,46,-23, 
  /* [28][1][][] */ -12,-23,-7,-31,-30,15,-18,4,16,-49,-35,-12,1,10,-44,9, 14,-30,-16,-28,16,23,-8,9,0,18,-2,-10,20,28,-33,-3, -21,-31,-33,112,43,4,-23,-11,-9,41,27,16,65,32,3,-29, 
  /* [28][2][][] */ -1,-54,-13,-63,-37,-5,-25,-22,11,-7,-56,-48,-44,-3,-38,-19, -9,-21,-21,4,17,33,-43,-19,23,5,1,11,3,11,19,-32, -16,-18,20,127,2,11,-16,8,-35,5,0,32,89,13,22,-7, 
  /* [29][0][][] */ 82,42,-12,-58,122,62,-38,21,51,-28,60,-35,33,-16,36,42, -23,-67,23,11,61,21,57,56,-17,-54,-96,47,64,-22,-10,-10, 43,-44,9,-35,-127,33,21,24,-2,33,-44,-42,-127,-34,-60,-36, 
  /* [29][1][][] */ 11,99,-67,-27,55,22,-49,-13,67,50,-7,58,8,33,4,50, 26,2,14,21,115,-31,28,34,-26,54,24,-75,40,-32,-25,2, 26,36,-10,-51,-86,20,22,1,-18,-57,-29,-67,-84,61,-69,-16, 
  /* [29][2][][] */ 30,80,-70,-1,83,0,-73,4,104,-7,59,93,-37,-5,-45,-12, 12,8,22,32,97,-28,-42,33,30,-10,-20,-19,101,-22,-29,47, 18,32,1,-67,-125,-8,2,6,-66,-36,-19,-17,-42,20,-82,23, 
  /* [30][0][][] */ 98,108,86,44,-54,20,71,99,-15,-73,29,-122,-9,120,-35,98, 41,78,95,6,-29,83,90,71,32,-38,-34,-36,-18,107,-9,70, 5,-23,28,-31,21,30,13,34,-5,106,21,34,61,62,24,25, 
  /* [30][1][][] */ 100,91,122,18,-50,98,56,86,-8,-121,-44,-90,-29,20,-58,103, 52,40,68,6,3,127,79,70,25,-53,-56,-2,15,90,3,71, 2,16,0,10,27,6,20,43,-7,43,35,91,92,48,19,4, 
  /* [30][2][][] */ 80,68,60,-25,-87,60,123,74,-3,-46,-82,-41,-43,105,-86,118, 5,-14,66,8,-3,92,93,25,-10,-37,-61,-7,24,93,-10,49, 42,42,5,48,2,37,15,12,-19,25,51,15,98,48,71,5, 
  /* [31][0][][] */ -6,-42,-16,3,-33,-25,21,-27,71,-3,-35,-8,5,-77,25,-15, -32,12,-68,35,-5,-15,-12,-49,-18,28,0,44,15,-9,58,-62, -13,31,-21,47,29,-29,-60,-62,-31,-2,-61,38,24,-49,66,-37, 
  /* [31][1][][] */ -71,-49,-34,11,-24,-23,27,-26,65,25,42,10,44,38,8,-15, -50,-37,-21,44,-28,-22,-12,-50,0,35,-4,49,-4,-46,50,-88, 6,-1,-35,22,51,-21,-22,-39,11,6,-7,13,31,-13,26,-25, 
  /* [31][2][][] */ -7,-44,-10,62,-42,-49,44,-54,127,25,47,-1,-4,-13,18,54, -52,3,-62,29,-15,-4,-18,-61,0,65,20,75,-8,-61,6,-65, -12,4,-14,-35,5,15,-5,-66,-22,0,-8,35,21,-26,64,-49, 
};
const TfArray<4, int> tensor_dimension6 = { 4, { 32, 3, 3, 16, } };
const TfArray<32, float> quant6_scale = { 32, { 0.0022522190120071173, 0.0031060564797371626, 0.0032551151234656572, 0.0040277633816003799, 0.0028134495951235294, 0.0019995535258203745, 0.0037463710177689791, 0.0030699672643095255, 0.0024222591891884804, 0.0026640326250344515, 0.00395565340295434, 0.0028000606689602137, 0.0023232386447489262, 0.0028469208627939224, 0.0027092210948467255, 0.0047487169504165649, 0.0023685349151492119, 0.0028297826647758484, 0.005803968757390976, 0.0034010743256658316, 0.0032343631610274315, 0.003352020401507616, 0.0026389081031084061, 0.002658219076693058, 0.0034047975204885006, 0.0020352425053715706, 0.0036971485242247581, 0.0030989169608801603, 0.0042246533557772636, 0.0026227307971566916, 0.002462548203766346, 0.003025995334610343, } };
const TfArray<32, int> quant6_zero = { 32, { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(8) int32_t tensor_data7[32] = { 
    -76, 161, 97, -88, 11, -224, 63, -3, -58, -131, 
    -32, -206, 14, 90, -106, 69, -151, -255, 17, 118, 
    98, -59, -89, -212, 65, -188, 65, 24, -20, 37, 
    -224, -154, 
};
const TfArray<1, int> tensor_dimension7 = { 1, { 32, } };
const TfArray<32, float> quant7_scale = { 32, { 0.00040141545468941331, 0.00055359583348035812, 0.00058016274124383926, 0.00071787263732403517, 0.00050144421402364969, 0.00035638260305859149, 0.00066771981073543429, 0.00054716359591111541, 0.00043172188452444971, 0.00047481345245614648, 0.00070502044400200248, 0.00049905787454918027, 0.00041407335083931684, 0.00050740980077534914, 0.00048286744276992977, 0.00084636901738122106, 0.00042214654968120158, 0.00050435523735359311, 0.0010344476904720068, 0.00060617720009759068, 0.0005764640518464148, 0.00059743423480540514, 0.00047033547889441252, 0.00047377729788422585, 0.00060684076743200421, 0.00036274347803555429, 0.0006589468102902174, 0.00055232335580512881, 0.00075296458089724183, 0.00046745216241106391, 0.00043890264350920916, 0.00053932645823806524, } };
const TfArray<32, int> quant7_zero = { 32, { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const ALIGN(8) int8_t tensor_data8[16*32] = { 
  75, 82, 10, 83, -98, -25, -6, 22, 74, 105, -9, -43, 93, -23, 12, -76, 76, 65, -58, -28, 18, -1, -14, 13, 25, 2, 31, -13, 4, 37, -41, -6, 
  -19, -78, -55, 40, 22, 7, 68, -65, -51, -30, 61, 45, -8, -19, 85, -27, 94, 20, 38, -36, -10, 76, -2, -2, 0, 48, 29, 78, 29, 27, 16, 54, 
  -12, 0, 13, -20, 87, 34, 4, 6, 29, -58, -37, -32, -61, 37, -12, 65, 11, -64, 113, -26, -1, 14, -6, -54, 55, 44, 36, 93, 14, -1, 0, -52, 
  67, -8, 78, 22, 25, 30, 45, 36, 76, 45, -94, -27, -16, 41, -115, 59, 60, -1, -7, 38, 61, -80, -73, 29, 36, -24, 29, 0, -12, -4, -107, -75, 
  31, 43, 50, -20, -37, -31, -4, 46, 14, -43, -127, -40, 43, 21, -87, -25, -75, 26, -1, 92, -7, -80, 19, -12, 23, -3, 36, -105, 59, -9, -44, -36, 
  10, 2, 54, 3, 45, -73, -53, 71, 6, 27, 63, 60, 9, 82, -1, -38, -36, 77, -60, 40, -9, -54, 59, 13, -78, -62, -33, -93, -65, -43, 45, 68, 
  10, 20, 30, -33, 6, -54, 16, -26, -32, -27, 112, 27, -16, 26, 56, 11, -80, 63, -26, -44, -68, 41, 43, 13, -37, 5, -50, -21, 15, -20, 23, 38, 
  -14, 29, -13, -1, 27, 20, -11, 68, 41, -13, -9, -42, 53, -87, -48, 57, -10, -30, 53, -43, 60, 75, -80, 79, 88, -42, 2, 5, -39, 49, -122, -38, 
  19, 36, 43, -13, 5, -84, -40, 13, -8, 20, 28, 91, -2, 91, 15, 57, -25, 29, 29, -2, -52, -21, 51, 26, -52, -38, -28, -96, 1, -43, 20, -22, 
  -34, -54, -21, -60, 11, -28, 83, -2, -55, -72, -63, 0, -31, 58, 58, 35, 15, -66, 89, -7, 72, -63, 14, -48, 44, -3, 1, -20, 48, 28, 38, 25, 
  29, -26, 36, 23, 8, -33, 5, -3, 27, 75, 28, 41, 4, 17, 58, -92, -13, 122, -93, 27, -104, 24, -4, 12, -57, 51, -50, -9, -18, -10, 7, -36, 
  -33, 48, -36, -2, 66, -5, -4, -53, 0, -61, 30, 55, 13, 46, 61, 40, -93, 5, 2, -39, -64, 46, 11, -43, -9, -40, -63, 61, -13, -32, 89, 24, 
  76, -23, -50, 127, -22, 16, -59, 13, 35, 3, 63, 74, 52, -41, 41, -20, 45, 31, -35, -32, 2, 27, -35, 35, -44, 71, -66, 58, -60, 89, -1, 14, 
  -80, -3, -24, -74, 69, -8, 73, -77, -42, -62, -19, 6, -56, 51, 42, 79, -53, -91, 60, 14, -49, -28, 24, -7, 52, -29, 22, -13, 61, -54, 24, 4, 
  -36, 20, -7, 39, -37, -9, 5, 49, 64, 26, -36, -7, -3, -69, 3, -11, 9, -40, 24, -5, 43, -12, -49, 2, -32, -36, -16, -46, -58, -6, -18, 4, 
  16, -47, -34, 80, 32, 51, -65, -82, -5, 27, 84, -15, -12, -47, 72, 9, 28, 4, 0, -30, 19, 120, 44, 57, 42, -8, -49, 102, 40, 7, 3, 46, 
};
const TfArray<2, int> tensor_dimension8 = { 2, { 16, 32, } };
const TfArray<1, float> quant8_scale = { 1, { 0.0059797889553010464, } };
const TfArray<1, int> quant8_zero = { 1, { 0, } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const ALIGN(8) int32_t tensor_data9[16] = { 
    76, -18, 56, 77, 80, 8, -18, 45, 42, 70, 
    -37, 9, -6, 51, -5, -79, 
};
const TfArray<1, int> tensor_dimension9 = { 1, { 16, } };
const TfArray<1, float> quant9_scale = { 1, { 0.0014338665641844273, } };
const TfArray<1, int> quant9_zero = { 1, { 0, } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const ALIGN(8) int8_t tensor_data10[4*16] = { 
  -127, 29, 33, -85, -16, 24, 59, -99, 24, 94, -106, 80, -94, 96, 12, 22, 
  -3, -105, 6, 12, 97, 44, -53, -33, 42, 25, 5, -79, -26, -38, -65, -85, 
  -27, 20, -95, -89, -69, 44, 80, -82, 27, -98, 93, 35, 43, -124, 45, 49, 
  -22, 48, 42, -8, -52, -74, -83, 14, -85, 50, -38, -44, 45, -45, -23, 59, 
};
const TfArray<2, int> tensor_dimension10 = { 2, { 4, 16, } };
const TfArray<1, float> quant10_scale = { 1, { 0.0094923991709947586, } };
const TfArray<1, int> quant10_zero = { 1, { 0, } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const ALIGN(8) int32_t tensor_data11[4] = { 
    -143, 74, -13, 59, 
};
const TfArray<1, int> tensor_dimension11 = { 1, { 4, } };
const TfArray<1, float> quant11_scale = { 1, { 0.0023563711438328028, } };
const TfArray<1, int> quant11_zero = { 1, { 0, } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<4, int> tensor_dimension12 = { 4, { 1, 128, 6, 16, } };
const TfArray<1, float> quant12_scale = { 1, { 0.0062226522713899612, } };
const TfArray<1, int> quant12_zero = { 1, { -128, } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<4, int> tensor_dimension13 = { 4, { 1, 42, 2, 16, } };
const TfArray<1, float> quant13_scale = { 1, { 0.0062226522713899612, } };
const TfArray<1, int> quant13_zero = { 1, { -128, } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<4, int> tensor_dimension14 = { 4, { 1, 42, 2, 16, } };
const TfArray<1, float> quant14_scale = { 1, { 0.1693672388792038, } };
const TfArray<1, int> quant14_zero = { 1, { -128, } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfArray<4, int> tensor_dimension15 = { 4, { 1, 42, 2, 16, } };
const TfArray<1, float> quant15_scale = { 1, { 0.17823109030723572, } };
const TfArray<1, int> quant15_zero = { 1, { -110, } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const TfArray<4, int> tensor_dimension16 = { 4, { 1, 42, 2, 32, } };
const TfArray<1, float> quant16_scale = { 1, { 0.35726615786552429, } };
const TfArray<1, int> quant16_zero = { 1, { -128, } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&quant16_zero, 0 };
const TfArray<4, int> tensor_dimension17 = { 4, { 1, 14, 2, 32, } };
const TfArray<1, float> quant17_scale = { 1, { 0.35726615786552429, } };
const TfArray<1, int> quant17_zero = { 1, { -128, } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&quant17_zero, 0 };
const TfArray<2, int> tensor_dimension18 = { 2, { 1, 32, } };
const TfArray<1, float> quant18_scale = { 1, { 0.23978547751903534, } };
const TfArray<1, int> quant18_zero = { 1, { -128, } };
const TfLiteAffineQuantization quant18 = { (TfLiteFloatArray*)&quant18_scale, (TfLiteIntArray*)&quant18_zero, 0 };
const TfArray<2, int> tensor_dimension19 = { 2, { 1, 16, } };
const TfArray<1, float> quant19_scale = { 1, { 0.24823768436908722, } };
const TfArray<1, int> quant19_zero = { 1, { -128, } };
const TfLiteAffineQuantization quant19 = { (TfLiteFloatArray*)&quant19_scale, (TfLiteIntArray*)&quant19_zero, 0 };
const TfArray<2, int> tensor_dimension20 = { 2, { 1, 4, } };
const TfArray<1, float> quant20_scale = { 1, { 0.58216392993927002, } };
const TfArray<1, int> quant20_zero = { 1, { 90, } };
const TfLiteAffineQuantization quant20 = { (TfLiteFloatArray*)&quant20_scale, (TfLiteIntArray*)&quant20_zero, 0 };
const TfArray<2, int> tensor_dimension21 = { 2, { 1, 4, } };
const TfArray<1, float> quant21_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant21_zero = { 1, { -128, } };
const TfLiteAffineQuantization quant21 = { (TfLiteFloatArray*)&quant21_scale, (TfLiteIntArray*)&quant21_zero, 0 };
const TfLiteConvParams opdata0 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs0 = { 3, { 0, 2, 3, } };
const TfArray<1, int> outputs0 = { 1, { 12, } };
const TfLitePoolParams opdata1 = { kTfLitePaddingValid, 3,3, 3,3, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs1 = { 1, { 12, } };
const TfArray<1, int> outputs1 = { 1, { 13, } };
const TfLiteMulParams opdata2 = { kTfLiteActNone };
const TfArray<2, int> inputs2 = { 2, { 13, 4, } };
const TfArray<1, int> outputs2 = { 1, { 14, } };
const TfLiteAddParams opdata3 = { kTfLiteActNone, 1 };
const TfArray<2, int> inputs3 = { 2, { 14, 5, } };
const TfArray<1, int> outputs3 = { 1, { 15, } };
const TfLiteConvParams opdata4 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs4 = { 3, { 15, 6, 7, } };
const TfArray<1, int> outputs4 = { 1, { 16, } };
const TfLitePoolParams opdata5 = { kTfLitePaddingValid, 1,3, 1,3, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs5 = { 1, { 16, } };
const TfArray<1, int> outputs5 = { 1, { 17, } };
const ALIGN(1) uint8_t opdata6[1] = { 0,  }; /* op type 40=MEAN */
const TfArray<2, int> inputs6 = { 2, { 17, 1, } };
const TfArray<1, int> outputs6 = { 1, { 18, } };
const TfLiteFullyConnectedParams opdata7 = { kTfLiteActRelu, kTfLiteFullyConnectedWeightsFormatDefault, 0, 0 };
const TfArray<3, int> inputs7 = { 3, { 18, 8, 9, } };
const TfArray<1, int> outputs7 = { 1, { 19, } };
const TfLiteFullyConnectedParams opdata8 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, 0, 0 };
const TfArray<3, int> inputs8 = { 3, { 19, 10, 11, } };
const TfArray<1, int> outputs8 = { 1, { 20, } };
const TfLiteSoftmaxParams opdata9 = { 1 };
const TfArray<1, int> inputs9 = { 1, { 20, } };
const TfArray<1, int> outputs9 = { 1, { 21, } };
const TensorInfo_t tensorData[] = {
  { kTfLiteInt8, tensor_arena + 12288, (TfLiteIntArray*)&tensor_dimension0, 768, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0)) },},
  { kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 8, {kTfLiteNoQuantization, nullptr },},
  { kTfLiteInt8, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 144, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant2)) },},
  { kTfLiteInt32, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant3)) },},
  { kTfLiteInt8, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 16, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant4)) },},
  { kTfLiteInt8, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 16, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant5)) },},
  { kTfLiteInt8, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 4608, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6)) },},
  { kTfLiteInt32, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 128, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7)) },},
  { kTfLiteInt8, (void*)tensor_data8, (TfLiteIntArray*)&tensor_dimension8, 512, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8)) },},
  { kTfLiteInt32, (void*)tensor_data9, (TfLiteIntArray*)&tensor_dimension9, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9)) },},
  { kTfLiteInt8, (void*)tensor_data10, (TfLiteIntArray*)&tensor_dimension10, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10)) },},
  { kTfLiteInt32, (void*)tensor_data11, (TfLiteIntArray*)&tensor_dimension11, 16, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11)) },},
  { kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension12, 12288, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12)) },},
  { kTfLiteInt8, tensor_arena + 12288, (TfLiteIntArray*)&tensor_dimension13, 1344, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13)) },},
  { kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension14, 1344, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14)) },},
  { kTfLiteInt8, tensor_arena + 2688, (TfLiteIntArray*)&tensor_dimension15, 1344, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant15)) },},
  { kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension16, 2688, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant16)) },},
  { kTfLiteInt8, tensor_arena + 2688, (TfLiteIntArray*)&tensor_dimension17, 896, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant17)) },},
  { kTfLiteInt8, tensor_arena + 128, (TfLiteIntArray*)&tensor_dimension18, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant18)) },},
  { kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension19, 16, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant19)) },},
  { kTfLiteInt8, tensor_arena + 16, (TfLiteIntArray*)&tensor_dimension20, 4, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant20)) },},
  { kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension21, 4, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant21)) },},
};
const NodeInfo_t nodeData[kOpNodesCount] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_MUL, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_ADD, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_MEAN, },
  { (TfLiteIntArray*)&inputs7, (TfLiteIntArray*)&outputs7, const_cast<void*>(static_cast<const void*>(&opdata7)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs8, (TfLiteIntArray*)&outputs8, const_cast<void*>(static_cast<const void*>(&opdata8)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs9, (TfLiteIntArray*)&outputs9, const_cast<void*>(static_cast<const void*>(&opdata9)), OP_SOFTMAX, },
};


  // Used by RequestScratchBufferInArena to generate buffer index
  // for each request.  Reset for each node from _init to allow
  // for nodes omitting calls as scratch buffer indexes is in pre-computed OpData
  int next_scratch_buffer_idx;
  const uint8_t node_scratch_buffer_requests[] = {
1, 0, 0, 0, 1, 0, 1, 0, 0, 0,

};  

const size_t scratchbuf_offsets[] = {
13056, 4032, 0, 
};  

void *AllocatePersistentBuffer(struct TfLiteContext* ignore,
                                                 size_t bytes) {
  static uint8_t *AllocPtr = tensor_arena + sizeof(tensor_arena);

  AllocPtr -= bytes;
  return AllocPtr;
}

TfLiteEvalTensor *GetEvalTensor(const struct TfLiteContext *ignore,
                                       int tensor_idx) {
  return &evalTensors[tensor_idx];
}

TfLiteStatus RequestScratchBufferInArena(TfLiteContext *ignored,
                                                size_t bytes_ignored,
                                                int *buffer_idx) {
  *buffer_idx = next_scratch_buffer_idx;
  ++next_scratch_buffer_idx;
  return kTfLiteOk;
}

void* GetScratchBuffer(struct TfLiteContext *ignore, int buffer_idx) {
  return tensor_arena + scratchbuf_offsets[buffer_idx];
}

} // namespace
#if TF_LITE_MICRO_USE_OFFLINE_OP_USER_DATA
namespace tflite {
namespace ops {
namespace micro {

namespace add {

OpData MAGIC_WAND_op_user_data[] = {
  {1, 0, -4, -128, 127, 1073741824, 1472831993, 2040684234, -19, 20, 128, -127, -110, 0.000000, 0.000000, EvalAddQuantized}
};
} // namespace add

namespace conv {

int32_t MAGIC_WAND_op_user_data0_per_channel_output_multiplier[] = {
1844055393, 1960712396, 1382233200, 1741790692, 1260139165, 1150098846, 1334519216, 1546318523, 1335624791, 1315232756, 2090797344, 1242480679, 1273437257, 1465497910, 1601916619, 1738378854, 
};
int32_t MAGIC_WAND_op_user_data0_per_channel_output_shift[] = {
-8, -8, -8, -8, -7, -7, -8, -8, -7, -7, -8, -7, -7, -8, -8, -8, 
};
int32_t MAGIC_WAND_op_user_data1_per_channel_output_multiplier[] = {
1235384167, 1703729956, 1785491404, 1104651698, 1543229618, 1096792432, 2054954432, 1683934348, 1328654379, 1461271621, 1084874863, 1535885542, 1274339762, 1561589233, 1486058340, 1302379943, 1299185611, 1552188612, 1591792599, 1865552751, 1774108566, 1838645758, 1447490352, 1458082781, 1867594993, 1116368503, 2027954976, 1699813797, 1158650611, 1438616797, 1350753655, 1659814923, 
};
int32_t MAGIC_WAND_op_user_data1_per_channel_output_shift[] = {
-9, -9, -9, -8, -9, -9, -9, -9, -9, -9, -8, -9, -9, -9, -9, -8, -9, -9, -8, -9, -9, -9, -9, -9, -9, -9, -9, -9, -8, -9, -9, -9, 
};
OpData MAGIC_WAND_op_user_data[] = {
  {{{1, 1, 0, 0}, 0, 0, -128, 0, 0, MAGIC_WAND_op_user_data0_per_channel_output_multiplier, MAGIC_WAND_op_user_data0_per_channel_output_shift, -128, 127}, 0, nullptr, -1, EvalQuantizedPerChannel}, 
  {{{1, 1, 0, 0}, -110, 0, -128, 0, 0, MAGIC_WAND_op_user_data1_per_channel_output_multiplier, MAGIC_WAND_op_user_data1_per_channel_output_shift, -128, 127}, 1, nullptr, -1, EvalQuantizedPerChannel}
};
} // namespace conv

namespace depthwise_conv {

OpData MAGIC_WAND_op_user_data[] = {
};
} // namespace depthwise_conv

namespace fully_connected {

OpData MAGIC_WAND_op_user_data[] = {
  {{1587745394, -7, -128, 127, 0, -128, 0, -128}, -1, nullptr, -1, -1, EvalQuantizedInt8}, 
  {{1112597904, -7, -128, 127, 0, -128, 0, 90}, -1, nullptr, -1, -1, EvalQuantizedInt8}
};
} // namespace fully_connected

namespace mul {

OpData MAGIC_WAND_op_user_data[] = {
  {{-128, -128, -128, 127, -128, 1382963341, -7, 0.000000, 0.000000}, EvalQuantized}
};
} // namespace mul

namespace pooling {

OpData MAGIC_WAND_op_user_data[] = {
  {{{0, 0, 0, 0}, -128, 127, 0.000000, 0.000000}, -1, MaxEvalInt8}, 
  {{{0, 0, 0, 0}, -128, 127, 0.000000, 0.000000}, -1, MaxEvalInt8}
};
} // namespace pooling

namespace softmax {

OpData MAGIC_WAND_op_user_data[] = {
  {{0.000000, 1250187520, 26, 0, 0, -31, 0, 0.000000, nullptr, nullptr, nullptr, nullptr, nullptr}, SoftmaxQuantizedInt8}
};
} // namespace softmax

namespace svdf {

OpData MAGIC_WAND_op_user_data[] = {
};
} // namespace svdf

} // namespace micro
} // namespace ops

namespace micro {
namespace MAGIC_WAND_model {
void *precomputed_op_user_data[] = {
  &tflite::ops::micro::conv::MAGIC_WAND_op_user_data[0],
  &tflite::ops::micro::pooling::MAGIC_WAND_op_user_data[0],
  &tflite::ops::micro::mul::MAGIC_WAND_op_user_data[0],
  &tflite::ops::micro::add::MAGIC_WAND_op_user_data[0],
  &tflite::ops::micro::conv::MAGIC_WAND_op_user_data[1],
  &tflite::ops::micro::pooling::MAGIC_WAND_op_user_data[1],
  &tflite::ops::micro::fully_connected::MAGIC_WAND_op_user_data[0],
  &tflite::ops::micro::fully_connected::MAGIC_WAND_op_user_data[1],
  &tflite::ops::micro::softmax::MAGIC_WAND_op_user_data[0],
};

} // namespace MAGIC_WAND_model
} // namespace micro
} // namespace tflite
#endif  // TF_LITE_MICRO_USE_OFFLINE_OP_USER_DATA

class MAGIC_WAND_PreinterpretedMicroContext : public tflite::MicroContext {
 public:
   MAGIC_WAND_PreinterpretedMicroContext() : 
    tflite::MicroContext(nullptr, nullptr, nullptr) {}

  // Allocate persistent buffer which has the same life time as the interpreter.
  // Returns nullptr on failure.
  // The memory is allocated from the tail.
  // This method is only available in Init or Prepare stage.
  // Virtual so that it can be faked for kernel tests.
  virtual void* AllocatePersistentBuffer(size_t bytes) {
    return ::AllocatePersistentBuffer(nullptr, bytes);
  }

  // Request a scratch buffer in the arena through static memory planning.
  // This method is only available in Prepare stage and the buffer is allocated
  // by the interpreter between Prepare and Eval stage. In Eval stage,
  // GetScratchBuffer API can be used to fetch the address.
  // Virtual so that it can be faked for kernel tests.
  virtual TfLiteStatus RequestScratchBufferInArena(size_t bytes,
                                                   int* buffer_idx) {
    return ::RequestScratchBufferInArena(nullptr, bytes, buffer_idx);
  }

  // Get the scratch buffer pointer.
  // This method is only available in Eval stage.
  // Virtual so that it can be faked for kernel tests.
  virtual void* GetScratchBuffer(int buffer_idx) {
    return ::GetScratchBuffer(nullptr, buffer_idx);
  }

  // Returns a temporary TfLiteTensor struct for a given index.
  // Virtual so that it can be faked for kernel tests.
  virtual TfLiteTensor* AllocateTempTfLiteTensor(int tensor_idx) {
    return tensor_idx >= 0 ? &tflTensors[tensor_idx] : nullptr;
  }

  // Returns a temporary TfLiteTensor struct for the specified input tensor of a
  // given mode. This is the recommended API over the deprecated
  // GetInput/GetInputSafe to get a temp input tensor. The returned tensor shall
  // be freed via calling DeallocateTempTfLiteTensor.
  virtual TfLiteTensor* AllocateTempInputTensor(const TfLiteNode* node,
                                                int index) {
    return AllocateTempTfLiteTensor(node->inputs->data[index]);
  }

  // Returns a temporary TfLiteTensor struct for the specified output tensor of
  // a given mode. This is the recommended API over the deprecated
  // GetOutput/GetOutputSafe to get a temp output tensor. The returned tensor
  // shall be freed via calling DeallocateTempTfLiteTensor.
  virtual TfLiteTensor* AllocateTempOutputTensor(const TfLiteNode* node,
                                                 int index) {
    return AllocateTempTfLiteTensor(node->outputs->data[index]);
  }

  // Deallocates a temp TfLiteTensor.
  // Virtual so that it can be faked for kernel tests.
  virtual void DeallocateTempTfLiteTensor(TfLiteTensor* tensor) {
    // No-op
  }

  // Returns a TfLiteEvalTensor struct for a given index.
  // Virtual so that it can be faked for kernel tests.
  virtual TfLiteEvalTensor* GetEvalTensor(int tensor_idx) {
    return ::GetEvalTensor(nullptr, tensor_idx);
  }


  // Does not take ownership of the pointer and the pointer must refer to valid
  // an object that outlive this class instance.
  // This can only be called once to set one external context.
  TfLiteStatus set_external_context(void* external_context_payload);

  void* external_context() { return external_context_payload_; }
protected:
  void* external_context_payload_ = nullptr;

  TF_LITE_REMOVE_VIRTUAL_DELETE
};

extern "C" TfLiteStatus MAGIC_WAND_init() {
  ctx.AllocatePersistentBuffer = &AllocatePersistentBuffer;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArena;
  ctx.GetScratchBuffer = &GetScratchBuffer;
  ctx.GetEvalTensor = &GetEvalTensor;
  ctx.tensors = tflTensors;
  ctx.tensors_size = 22;

  static MAGIC_WAND_PreinterpretedMicroContext u_ctx;
  ctx.impl_ = static_cast<void *>(&u_ctx);

  TfLiteIntArray dimsEmptyTensor = {0};
  tflTensors[-1].dims = &dimsEmptyTensor;
  tflTensors[-1].data.raw = nullptr;
  for(size_t i = 0; i < 22; ++i) {
    tflTensors[i].data.data = tensorData[i].data;
    evalTensors[i].data.data = tensorData[i].data;
    tflTensors[i].type = tensorData[i].type;
    evalTensors[i].type = tensorData[i].type;
    tflTensors[i].is_variable = false;
    tflTensors[i].allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
    tflTensors[i].bytes = tensorData[i].bytes;
    tflTensors[i].dims = tensorData[i].dims;
    evalTensors[i].dims = tensorData[i].dims;
    tflTensors[i].quantization = tensorData[i].quantization;
    if (tflTensors[i].quantization.type == kTfLiteAffineQuantization) {
      TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
      tflTensors[i].params.scale = quant->scale->data[0];
      tflTensors[i].params.zero_point = quant->zero_point->data[0];
    } else if (tflTensors[i].quantization.type == kTfLitePackedAffineQuantization) {
      TfLitePackedAffineQuantization const* quant = (TfLitePackedAffineQuantization const*)(tensorData[i].quantization.params);
      tflTensors[i].params.scale = quant->affine.scale->data[0];
      tflTensors[i].params.zero_point = quant->affine.zero_point->data[0];
    }
  }
  registrations[OP_CONV_2D] = tflite::Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = tflite::Register_MAX_POOL_2D();
  registrations[OP_MUL] = tflite::Register_MUL();
  registrations[OP_ADD] = tflite::Register_ADD();
  registrations[OP_MEAN] = tflite::ops::micro::Register_MEAN();
  registrations[OP_FULLY_CONNECTED] = tflite::Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = tflite::Register_SOFTMAX();


#if TF_LITE_MICRO_USE_OFFLINE_OP_USER_DATA
tflite::micro::resetOfflineOpUserData( tflite::micro::MAGIC_WAND_model::precomputed_op_user_data);
#endif  // TF_LITE_MICRO_USE_OFFLINE_OP_USER_DATA
  for(size_t i = 0; i < kOpNodesCount; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
    tflNodes[i].custom_initial_data = nullptr;
    tflNodes[i].custom_initial_data_size = 0;
    if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }

#if TF_LITE_MICRO_USE_OFFLINE_OP_USER_DATA
tflite::micro::resetOfflineOpUserData( tflite::micro::MAGIC_WAND_model::precomputed_op_user_data);
#endif  // TF_LITE_MICRO_USE_OFFLINE_OP_USER_DATA
  size_t precomputed_sb_idx_ctr = 0;
  
  for(size_t i = 0; i < kOpNodesCount; ++i) {
    next_scratch_buffer_idx = precomputed_sb_idx_ctr;
    if (registrations[nodeData[i].used_op_index].prepare) {
      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
    precomputed_sb_idx_ctr += node_scratch_buffer_requests[i];
  }
  return kTfLiteOk;
}

extern "C" TfLiteTensor* MAGIC_WAND_input(int index) {  
    static const int inTensorIndices[] = {
    0, 
    };
    return &ctx.tensors[inTensorIndices[index]];
  }

extern "C" TfLiteTensor* MAGIC_WAND_output(int index) {
    static const int outTensorIndices[] = {
    21, 
    };
    return &ctx.tensors[outTensorIndices[index]];
  }
  

// Returns the number of input tensors.
extern "C" size_t MAGIC_WAND_inputs() {
  return 1;
}
// Returns the number of output tensors.
extern "C" size_t MAGIC_WAND_outputs() {
  return 1;
}

extern "C" void *MAGIC_WAND_input_ptr(int index) {
  return MAGIC_WAND_input(index)->data.data;
}
extern "C" size_t MAGIC_WAND_input_size(int index) {
  return MAGIC_WAND_input(index)->bytes;
}
extern "C" int MAGIC_WAND_input_dims_len(int index) {
  return MAGIC_WAND_input(index)->dims->size;
}
extern "C" int *MAGIC_WAND_input_dims(int index) {
  return &MAGIC_WAND_input(index)->dims->data[0];
}

extern "C" void *MAGIC_WAND_output_ptr(int index) {
  return MAGIC_WAND_output(index)->data.data;
}
extern "C" size_t MAGIC_WAND_output_size(int index) {
  return MAGIC_WAND_output(index)->bytes;
}
extern "C" int MAGIC_WAND_output_dims_len(int index) {
  return MAGIC_WAND_output(index)->dims->size;
}
extern "C" int *MAGIC_WAND_output_dims(int index) {
  return &MAGIC_WAND_output(index)->dims->data[0];
}



extern "C" TfLiteStatus MAGIC_WAND_invoke() {

#if TF_LITE_MICRO_USE_OFFLINE_OP_USER_DATA
tflite::micro::resetOfflineOpUserData( tflite::micro::MAGIC_WAND_model::precomputed_op_user_data);
#endif  // TF_LITE_MICRO_USE_OFFLINE_OP_USER_DATA

  for(size_t i = 0; i < kOpNodesCount; ++i) {
#if LOG_OP_INPUTS
    tflite::logOpInvoke(&ctx,  &tflNodes[i]);
#endif
    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);
    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

